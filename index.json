[{"authors":["admin"],"categories":null,"content":"I am currently a Machine Learning Enginner at OakNorth working on various computer vision models. Before that I worked for Bloomberg where I used market transaction data to better model users and their needs.\nI graduated with MEng from University of Cambridge. My supervisor was the amazing Prof Liò. During my time here, I was associated with Fizwilliam College and my DoS was Dr Harle.\nFeel free to explore further. Apologies, this site is still under construction.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1587077318,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/author/laurynas-karazija/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/laurynas-karazija/","section":"authors","summary":"I am currently a Machine Learning Enginner at OakNorth working on various computer vision models. Before that I worked for Bloomberg where I used market transaction data to better model users and their needs.","tags":null,"title":"Laurynas Karazija","type":"authors"},{"authors":["Laurynas Karazija","Petar Veličković","Pietro Liò"],"categories":[],"content":"","date":1525284977,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1525284977,"objectID":"fce86809fc9e25276b3467c183255794","permalink":"/publication/karazija2018/","publishdate":"2020-08-16T17:15:49+01:00","relpermalink":"/publication/karazija2018/","section":"publication","summary":"This paper introduces a way to learn cross-modal convolutional neural network (X-CNN) architectures from a base convolutional network (CNN) and the training data to reduce the design cost and enable applying cross-modal networks in sparse data environments. Two approaches for building X-CNNs are presented. The base approach learns the topology in a data-driven manner, by using measurements performed on the base CNN and supplied data. The iterative approach performs further optimisation of the topology through a combined learning procedure, simultaneously learning the topology and training the network. The approaches were evaluated agains examples of hand-designed X-CNNs and their base variants, showing superior performance and, in some cases, gaining an additional 9% of accuracy. From further considerations, we conclude that the presented methodology takes less time than any manual approach would, whilst also significantly reducing the design complexity. The application of the methods is fully automated and implemented in Xsertion library.","tags":[],"title":"Automatic Inference of Cross-modal Connection Topologies for X-CNNs","type":"publication"},{"authors":["Petar Veličković","Laurynas Karazija","Nicholas D Lane","Sourav Bhattacharya","Edgar Liberis","Pietro Liò","Angela Chieh","Otmane Bellahsen","Matthieu Vegreville"],"categories":[],"content":"","date":1511937928,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1511937928,"objectID":"83aca2f5215e1b51852561e8e5f52a42","permalink":"/publication/velickovic18cross/","publishdate":"2020-08-16T17:16:08+01:00","relpermalink":"/publication/velickovic18cross/","section":"publication","summary":"We analyse multimodal time-series data corresponding to weight, sleep and steps measurements. We focus on predicting whether a user will successfully achieve his/her weight objective. For this, we design several deep long short-term memory (LSTM) architectures, including a novel cross-modal LSTM (X-LSTM), and demonstrate their superiority over baseline approaches. The X-LSTM improves parameter efficiency by processing each modality separately and allowing for information flow between them by way of recurrent cross-connections. We present a general hyperparameter optimisation technique for X-LSTMs, which allows us to significantly improve on the LSTM and a prior state-of-the-art cross-modal approach, using a comparable number of parameters. Finally, we visualise the model's predictions, revealing implications about latent variables in this task.","tags":[],"title":"Cross-modal Recurrent Models for Weight Objective Prediction from Multimodal Time-series Data","type":"publication"}]