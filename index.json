[{"authors":["admin"],"categories":null,"content":"I am currently a DPhil (PhD) student at University of Oxford, AIMS CDT, advised by Prof A. Vedaldi, Dr C. Rupprecht, and Dr I. Laina at VGG. I am broadly interested in unsupervised scene understanding, with emphasis on objects.\nIn previous life, I worked as MLE for OakNorth and Bloomberg. I graduated with MEng in Computer Science from University of Cambridge, supervised by Prof Liò. Feel free to explore further. Apologies, this site is still under construction.\n","date":-62135596800,"expirydate":-62135596800,"kind":"term","lang":"en","lastmod":1641237554,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"https://karazijal.github.io/author/laurynas-karazija/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/laurynas-karazija/","section":"authors","summary":"I am currently a DPhil (PhD) student at University of Oxford, AIMS CDT, advised by Prof A. Vedaldi, Dr C. Rupprecht, and Dr I. Laina at VGG. I am broadly interested in unsupervised scene understanding, with emphasis on objects.","tags":null,"title":"Laurynas Karazija","type":"authors"},{"authors":["Laurynas Karazija","Iro Laina","Christian Rupprecht"],"categories":[],"content":"","date":1630260977,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1641245644,"objectID":"b662928ff9f93365a2d03db244d1d50f","permalink":"https://karazijal.github.io/publication/karazija2021clevrtex/","publishdate":"2022-01-02T17:15:49+01:00","relpermalink":"/publication/karazija2021clevrtex/","section":"publication","summary":"There has been a recent surge in methods that aim to decompose and segment scenes into multiple objects in an unsupervised manner, i.e., unsupervised multi-object segmentation. Performing such a task is a long-standing goal of computer vision, offering to unlock object-level reasoning without requiring dense annotations to train segmentation models. Despite significant progress, current models are developed and trained on visually simple scenes depicting mono-colored objects on plain backgrounds. The natural world, however, is visually complex with confounding aspects such as diverse textures and complicated lighting effects. In this study, we present a new benchmark called ClevrTex, designed as the next challenge to compare, evaluate and analyze algorithms. ClevrTex features synthetic scenes with diverse shapes, textures and photo-mapped materials, created using physically based rendering techniques. ClevrTex has 50k examples depicting 3-10 objects arranged on a background, created using a catalog of 60 materials, and a further test set featuring 10k images created using 25 different materials. We benchmark a large set of recent unsupervised multi-object segmentation models on ClevrTex and find all state-of-the-art approaches fail to learn good representations in the textured setting, despite impressive performance on simpler data. We also create variants of the ClevrTex dataset, controlling for different aspects of scene complexity, and probe current approaches for individual shortcomings.","tags":[],"title":"ClevrTex: A Texture-Rich Benchmark for Unsupervised Multi-Object Segmentation","type":"publication"},{"authors":["Laurynas Karazija","Petar Veličković","Pietro Liò"],"categories":[],"content":"","date":1525284977,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597600475,"objectID":"fce86809fc9e25276b3467c183255794","permalink":"https://karazijal.github.io/publication/karazija2018/","publishdate":"2020-08-16T17:15:49+01:00","relpermalink":"/publication/karazija2018/","section":"publication","summary":"This paper introduces a way to learn cross-modal convolutional neural network (X-CNN) architectures from a base convolutional network (CNN) and the training data to reduce the design cost and enable applying cross-modal networks in sparse data environments. Two approaches for building X-CNNs are presented. The base approach learns the topology in a data-driven manner, by using measurements performed on the base CNN and supplied data. The iterative approach performs further optimisation of the topology through a combined learning procedure, simultaneously learning the topology and training the network. The approaches were evaluated agains examples of hand-designed X-CNNs and their base variants, showing superior performance and, in some cases, gaining an additional 9% of accuracy. From further considerations, we conclude that the presented methodology takes less time than any manual approach would, whilst also significantly reducing the design complexity. The application of the methods is fully automated and implemented in Xsertion library.","tags":[],"title":"Automatic Inference of Cross-modal Connection Topologies for X-CNNs","type":"publication"},{"authors":["Petar Veličković","Laurynas Karazija","Nicholas D Lane","Sourav Bhattacharya","Edgar Liberis","Pietro Liò","Angela Chieh","Otmane Bellahsen","Matthieu Vegreville"],"categories":[],"content":"","date":1511937928,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1597599573,"objectID":"83aca2f5215e1b51852561e8e5f52a42","permalink":"https://karazijal.github.io/publication/velickovic18cross/","publishdate":"2020-08-16T17:16:08+01:00","relpermalink":"/publication/velickovic18cross/","section":"publication","summary":"We analyse multimodal time-series data corresponding to weight, sleep and steps measurements. We focus on predicting whether a user will successfully achieve his/her weight objective. For this, we design several deep long short-term memory (LSTM) architectures, including a novel cross-modal LSTM (X-LSTM), and demonstrate their superiority over baseline approaches. The X-LSTM improves parameter efficiency by processing each modality separately and allowing for information flow between them by way of recurrent cross-connections. We present a general hyperparameter optimisation technique for X-LSTMs, which allows us to significantly improve on the LSTM and a prior state-of-the-art cross-modal approach, using a comparable number of parameters. Finally, we visualise the model's predictions, revealing implications about latent variables in this task.","tags":[],"title":"Cross-modal Recurrent Models for Weight Objective Prediction from Multimodal Time-series Data","type":"publication"}]