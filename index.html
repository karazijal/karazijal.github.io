<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=generator content="Source Themes Academic 4.8.0"><meta name=author content="Laurynas Karazija"><meta name=description content="DPhil student at:"><link rel=alternate hreflang=en-us href=https://karazijal.github.io/><meta name=theme-color content="rgb(72, 145, 220)"><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.0-1/css/all.min.css integrity="sha256-4w9DunooKSr3MFXHXWyFER38WmPdm361bQS/2KUWZbU=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.css integrity="sha256-Vzbj7sDDS/woiFS3uNKo8eIuni59rjyNGtXfstRzStA=" crossorigin=anonymous><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/github.min.css crossorigin=anonymous title=hl-light disabled><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/styles/dracula.min.css crossorigin=anonymous title=hl-dark><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.css integrity="sha256-SHMGCYmST46SoyGgo4YR/9AlK1vf3ff84Aq9yK4hdqM=" crossorigin=anonymous><script src=https://cdnjs.cloudflare.com/ajax/libs/lazysizes/5.1.2/lazysizes.min.js integrity="sha256-Md1qLToewPeKjfAHU1zyPwOutccPAm5tahnaw7Osw0A=" crossorigin=anonymous async></script>
<link rel=stylesheet href="https://fonts.googleapis.com/css?family=Montserrat:400,700%7CRoboto:400,400italic,700%7CRoboto+Mono&display=swap"><link rel=stylesheet href=/css/academic.css><script src=https://identity.netlify.com/v1/netlify-identity-widget.js></script>
<link rel=alternate href=/index.xml type=application/rss+xml title="Laurynas Karazija"><link rel=manifest href=/index.webmanifest><link rel=icon type=image/png href=/images/icon_huc6fce80a34933c4bd6173d931cb740e2_436901_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/images/icon_huc6fce80a34933c4bd6173d931cb740e2_436901_192x192_fill_lanczos_center_3.png><link rel=canonical href=https://karazijal.github.io/><meta property="twitter:card" content="summary"><meta property="og:site_name" content="Laurynas Karazija"><meta property="og:url" content="https://karazijal.github.io/"><meta property="og:title" content="Laurynas Karazija"><meta property="og:description" content="DPhil student at:"><meta property="og:image" content="https://karazijal.github.io/images/icon_huc6fce80a34933c4bd6173d931cb740e2_436901_512x512_fill_lanczos_center_3.png"><meta property="twitter:image" content="https://karazijal.github.io/images/icon_huc6fce80a34933c4bd6173d931cb740e2_436901_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><meta property="og:updated_time" content="2022-10-16T19:16:17+01:00"><script type=application/ld+json>{"@context":"https://schema.org","@type":"WebSite","potentialAction":{"@type":"SearchAction","target":"https://karazijal.github.io?q={search_term_string}","query-input":"required name=search_term_string"},"url":"https://karazijal.github.io"}</script><title>Laurynas Karazija</title></head><body id=top data-spy=scroll data-offset=70 data-target=#navbar-main class=dark><aside class=search-results id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=#><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>Laurynas Karazija</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>Laurynas Karazija</a></div><div class="navbar-collapse main-menu-item collapse justify-content-start" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/#about data-target=#about><span>Home</span></a></li><li class=nav-item><a class=nav-link href=/#publications data-target=#publications><span>Publications</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class="nav-link js-theme-selector" data-toggle=dropdown aria-haspopup=true><i class="fas fa-palette" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span></a>
<a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span></a>
<a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav><span class="js-widget-page d-none"></span><section id=about class="home-section wg-about"><div class=container><div class=row><div class="col-12 col-lg-4"><div id=profile><img class="avatar avatar-circle" src=/author/laurynas-karazija/avatar_hu2d8279aec2a8417f079c569f4a69d9eb_645305_270x270_fill_lanczos_center_3.png alt="Laurynas Karazija"><div class=portrait-title><h2>Laurynas Karazija</h2><h3>DPhil student at:</h3><h3><a href=https://www.robots.ox.ac.uk/~vgg/ target=_blank rel=noopener><span>Visual Geometry Group</span></a></h3><h3><a href=https://www.ox.ac.uk target=_blank rel=noopener><span>University of Oxford</span></a></h3><h3><a href=https://aims.robots.ox.ac.uk target=_blank rel=noopener><span>CDT in Autonomous Intelligent Machines and Systems</span></a></h3></div><ul class=network-icon aria-hidden=true><li><a href=/#mailto:laurynas@robots.ox.ac.uk><i class="fas fa-envelope big-icon"></i></a></li><li><a href=https://twitter.com/LKarazija target=_blank rel=noopener><i class="fab fa-twitter big-icon"></i></a></li><li><a href=https://github.com/karazijal target=_blank rel=noopener><i class="fab fa-github big-icon"></i></a></li><li><a href=https://linkedin.com/in/laurynas-karazija-b9591b103/ target=_blank rel=noopener><i class="fab fa-linkedin-in big-icon"></i></a></li></ul></div></div><div class="col-12 col-lg-8"><h1>About</h1><p>I am currently a DPhil (PhD) student at University of Oxford,
<a href=https://aims.robots.ox.ac.uk target=_blank rel=noopener>AIMS CDT</a>, advised by
<a href=https://www.robots.ox.ac.uk/~vedaldi/ target=_blank rel=noopener>Prof A. Vedaldi</a>,
<a href=https://chrirupp.github.io target=_blank rel=noopener>Dr C. Rupprecht</a>, and
<a href="https://scholar.google.de/citations?user=n9nXAPcAAAAJ&amp;hl=en" target=_blank rel=noopener>Dr I. Laina</a> at
<a href=https://www.robots.ox.ac.uk/~vgg/ target=_blank rel=noopener>VGG</a>.
I am broadly interested in unsupervised scene understanding, with emphasis on objects.</p><p>In previous life, I worked as MLE for OakNorth and Bloomberg. I graduated with MEng in Computer Science from University of Cambridge, supervised by
<a href=https://www.cl.cam.ac.uk/~pl219/ target=_blank rel=noopener>Prof Liò</a>.</p><p>I am always happy to discuss research, so feel free to reach out!</p><div class=row><div class=col-md-5><h3>Interests</h3><ul class=ul-interests><li>Unsupervised methods</li><li>Generative models</li><li>Computer vision</li><li>Scene understanding</li></ul></div><div class=col-md-7><h3>Education</h3><ul class="ul-edu fa-ul"><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>DPhil, (ongoing)</p><p class=institution>University of Oxford</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>MEng in Computer Science, 2017</p><p class=institution>University of Cambridge</p></div></li><li><i class="fa-li fas fa-graduation-cap"></i><div class=description><p class=course>BA in Computer Science, 2017</p><p class=institution>University of Cambridge</p></div></li></ul></div></div></div></div></div></section><section id=publications class="home-section wg-pages"><div class=container><div class=row><div class="col-12 col-lg-4 section-heading"><h1>Publications</h1></div><div class="col-12 col-lg-8"><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/karazija2022unsupervised/>Unsupervised Multi-object Segmentation by Predicting Probable Motion Patterns</a></h3><a href=/publication/karazija2022unsupervised/ class=summary-link><div class=article-style>We propose a new approach to learn to segment multiple image objects without manual supervision. The method can extract objects form …</div></a><div class="stream-meta article-metadata"><div><span>Laurynas Karazija*</span>, <span>Subhabrata Choudhury*</span>, <span>Iro Laina</span>, <span>Christian Rupprecht</span>, <span>Andrea Vedaldi</span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://arxiv.org/abs/2210.12148 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://github.com/karazijal/probable-motion target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.robots.ox.ac.uk/~vgg/research/ppmp/ target=_blank rel=noopener>Project</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://slideslive.com/embed/presentation/38992430?embed_parent_url=https%3A%2F%2Fwww.robots.ox.ac.uk%2F~vgg%2Fresearch%2Fppmp%2F&amp;embed_origin=https%3A%2F%2Fwww.robots.ox.ac.uk&amp;embed_container_id=presentation-embed-38992430&amp;auto_load=true&amp;auto_play=false&amp;zoom_ratio=&amp;disable_fullscreen=false&amp;locale=en&amp;vertical_enabled=true&amp;vertical_enabled_on_mobile=false&amp;allow_hidden_controls_when_paused=false&amp;fit_to_viewport=true&amp;custom_user_id=&amp;user_uuid=8a339d92-ccf6-46ae-a2c1-f8126010c951" target=_blank rel=noopener>Video</a></div></div><div class=ml-3><a href=/publication/karazija2022unsupervised/><img src=/publication/karazija2022unsupervised/featured_hu39a74584debadea9c436d5250a9fb87d_117759_150x0_resize_lanczos_3.png alt="Unsupervised Multi-object Segmentation by Predicting Probable Motion Patterns"></a></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/choudhury+karazija2022guess/>Guess What Moves: Unsupervised Video and Image Segmentation by Anticipating Motion</a></h3><a href=/publication/choudhury+karazija2022guess/ class=summary-link><div class=article-style>Motion, measured via optical flow, provides a powerful cue to discover and learn objects in images and videos. However, compared to …</div></a><div class="stream-meta article-metadata"><div><span>Subhabrata Choudhury*</span>, <span>Laurynas Karazija*</span>, <span>Iro Laina</span>, <span>Andrea Vedaldi</span>, <span>Christian Rupprecht</span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://arxiv.org/abs/2205.07844 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://github.com/karazijal/guess-what-moves target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.robots.ox.ac.uk/~vgg/research/gwm/ target=_blank rel=noopener>Project</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://youtu.be/wKKmRzaZmFg target=_blank rel=noopener>Video</a></div></div><div class=ml-3><a href=/publication/choudhury+karazija2022guess/><img src=/publication/choudhury+karazija2022guess/featured_hu301d492d692aa854fe42346b1e2120a9_1366131_150x0_resize_lanczos_3.png alt="Guess What Moves: Unsupervised Video and Image Segmentation by Anticipating Motion"></a></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/karazija2021clevrtex/>ClevrTex: A Texture-Rich Benchmark for Unsupervised Multi-Object Segmentation</a></h3><a href=/publication/karazija2021clevrtex/ class=summary-link><div class=article-style>There has been a recent surge in methods that aim to decompose and segment scenes into multiple objects in an unsupervised manner, …</div></a><div class="stream-meta article-metadata"><div><span><a href=/author/laurynas-karazija/>Laurynas Karazija</a></span>, <span>Iro Laina</span>, <span>Christian Rupprecht</span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://arxiv.org/abs/2111.10265 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://github.com/karazijal/clevrtex-generation target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://www.robots.ox.ac.uk/~vgg/data/clevrtex/ target=_blank rel=noopener>Project</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=/publication/karazija2021clevrtex/clevrtex_poster_fixed.png target=_blank rel=noopener>Poster</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href="https://slideslive.com/embed/presentation/38969525?embed_parent_url=https%3A%2F%2Fneurips.cc%2Fvirtual%2F2021%2Fdatasets-and-benchmarks%2F38449%23collapse-sl-29871&amp;embed_container_origin=https%3A%2F%2Fneurips.cc&amp;embed_container_id=presentation-embed-38969525" target=_blank rel=noopener>Video</a></div></div><div class=ml-3><a href=/publication/karazija2021clevrtex/><img src=/publication/karazija2021clevrtex/featured_hu0513aeea77e4196621310c69564f691e_4298930_150x0_resize_lanczos_3.png alt="ClevrTex: A Texture-Rich Benchmark for Unsupervised Multi-Object Segmentation"></a></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/karazija2018/>Automatic Inference of Cross-modal Connection Topologies for X-CNNs</a></h3><a href=/publication/karazija2018/ class=summary-link><div class=article-style>This paper introduces a way to learn cross-modal convolutional neural network (X-CNN) architectures from a base convolutional network …</div></a><div class="stream-meta article-metadata"><div><span><a href=/author/laurynas-karazija/>Laurynas Karazija</a></span>, <span>Petar Veličković</span>, <span>Pietro Liò</span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://arxiv.org/pdf/1805.00987.pdf target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://github.com/karazijal/xsertion target=_blank rel=noopener>Code</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=/publication/karazija2018/presentation.pdf target=_blank rel=noopener>Slides</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1007/978-3-319-92537-0_7 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3></div></div><div class="media stream-item"><div class=media-body><h3 class="article-title mb-0 mt-0"><a href=/publication/velickovic18cross/>Cross-modal Recurrent Models for Weight Objective Prediction from Multimodal Time-series Data</a></h3><a href=/publication/velickovic18cross/ class=summary-link><div class=article-style>We analyse multimodal time-series data corresponding to weight, sleep and steps measurements. We focus on predicting whether a user …</div></a><div class="stream-meta article-metadata"><div><span>Petar Veličković</span>, <span><a href=/author/laurynas-karazija/>Laurynas Karazija</a></span>, <span>Nicholas D Lane</span>, <span>Sourav Bhattacharya</span>, <span>Edgar Liberis</span>, <span>Pietro Liò</span>, <span>Angela Chieh</span>, <span>Otmane Bellahsen</span>, <span>Matthieu Vegreville</span></div></div><div class=btn-links><a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://dl.acm.org/doi/abs/10.1145/3240925.3240937 target=_blank rel=noopener>PDF</a>
<a class="btn btn-outline-primary my-1 mr-1 btn-sm" href=https://doi.org/10.1145/3240925.3240937 target=_blank rel=noopener>DOI</a></div></div><div class=ml-3></div></div></div></div></div></section><script src=https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.imagesloaded/4.1.4/imagesloaded.pkgd.min.js integrity="sha256-lqvxZrPLtfffUl2G/e7szqSvPBILGbwmsGE1MKlOi0Q=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/jquery.isotope/3.0.6/isotope.pkgd.min.js integrity="sha256-CBrpuqrMhXwcLLUd5tvQ4euBHCdh7wGlDfNz8vbu/iI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/fancybox/3.5.7/jquery.fancybox.min.js integrity="sha256-yt2kYMy0w8AbtF89WXb2P1rfjcP/HTHLT7097U8Y5b8=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/instant.page/5.1.0/instantpage.min.js integrity="sha512-1+qUtKoh9XZW7j+6LhRMAyOrgSQKenQ4mluTR+cvxXjP1Z54RxZuzstR/H9kgPXQsVB8IW7DMDFUJpzLjvhGSQ==" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/highlight.min.js integrity="sha256-eOgo0OtLL4cdq7RdwRUiGKLX9XsIJ7nGhWEKbohmVAQ=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.1/languages/r.min.js></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/leaflet/1.5.1/leaflet.js integrity="sha256-EErZamuLefUnbMBQbsEqu1USa+btR2oIlCpBJbyD4/g=" crossorigin=anonymous></script>
<script>const code_highlighting=!0</script><script>const isSiteThemeDark=!0</script><script>const search_config={indexURI:"/index.json",minLength:1,threshold:.3},i18n={no_results:"No results found",placeholder:"Search...",results:"results found"},content_type={post:"Posts",project:"Projects",publication:"Publications",talk:"Talks",slides:"Slides"}</script><script id=search-hit-fuse-template type=text/x-template>
      <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
      </div>
    </script><script src=https://cdnjs.cloudflare.com/ajax/libs/fuse.js/3.2.1/fuse.min.js integrity="sha256-VzgmKYmhsGNNN4Ph1kMW+BjoYJM2jV5i4IlFoeZA9XI=" crossorigin=anonymous></script>
<script src=https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/jquery.mark.min.js integrity="sha256-4HLtjeVgH0eIB3aZ9mLYF6E8oU5chNdjU6p6rrXpl9U=" crossorigin=anonymous></script>
<script>window.netlifyIdentity&&window.netlifyIdentity.on("init",e=>{e||window.netlifyIdentity.on("login",()=>{document.location.href="/admin/"})})</script><script src=/js/academic.min.0d53a7f39b7d6770128a54b39dad2f22.js></script><div class=container><footer class=site-footer><p class=powered-by>© Laurynas Karazija 2023</p><p class=powered-by>Published with
<a href=https://sourcethemes.com/academic/ target=_blank rel=noopener>Academic Website Builder</a>
<span class=float-right aria-hidden=true><a href=# class=back-to-top><span class=button_icon><i class="fas fa-chevron-up fa-2x"></i></span></a></span></p></footer></div><div id=modal class="modal fade" role=dialog><div class=modal-dialog><div class=modal-content><div class=modal-header><h5 class=modal-title>Cite</h5><button type=button class=close data-dismiss=modal aria-label=Close>
<span aria-hidden=true>&#215;</span></button></div><div class=modal-body><pre><code class="tex hljs"></code></pre></div><div class=modal-footer><a class="btn btn-outline-primary my-1 js-copy-cite" href=# target=_blank><i class="fas fa-copy"></i> Copy</a>
<a class="btn btn-outline-primary my-1 js-download-cite" href=# target=_blank><i class="fas fa-download"></i> Download</a><div id=modal-error></div></div></div></div></div></body></html>